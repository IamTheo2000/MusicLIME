{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e4e85d",
   "metadata": {},
   "source": [
    "## Model Related\n",
    "\n",
    "This notebook contains information on the models trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6643cb9",
   "metadata": {},
   "source": [
    "#### Model Architecture\n",
    "\n",
    "The models had the following architecture. More information about the training process can be found in the train notebooks. We cannot provide the lyrics or the audios used to train the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForAudioClassification, ASTModel, RobertaModel\n",
    "import torch.nn as nn\n",
    "\n",
    "# Language model\n",
    "AutoModelForSequenceClassification.from_pretrained('roberta-large', num_labels=9).to(device)\n",
    "\n",
    "# Audio model\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\", num_labels=9, ignore_mismatched_sizes=True)\n",
    "\n",
    "# The multimodal model consists of these two classes\n",
    "class CombinedClassificationHead(nn.Module):\n",
    "    def __init__(self, audio_feature_size, text_feature_size, num_labels):\n",
    "        super().__init__()\n",
    "        combined_feature_size = audio_feature_size + text_feature_size\n",
    "        self.layer_norm = nn.LayerNorm(combined_feature_size)\n",
    "        self.fc = nn.Linear(combined_feature_size, num_labels)\n",
    "\n",
    "    def forward(self, combined_features):\n",
    "        normalized_features = self.layer_norm(combined_features)\n",
    "        logits = self.fc(normalized_features)\n",
    "        return logits\n",
    "\n",
    "class AudioTextClassificationModel(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.audio_model = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        self.text_model = RobertaModel.from_pretrained('roberta-large')\n",
    "\n",
    "        audio_feature_size = self.audio_model.config.hidden_size\n",
    "        text_feature_size = self.text_model.config.hidden_size\n",
    "\n",
    "        self.classifier = CombinedClassificationHead(audio_feature_size, text_feature_size, num_labels)\n",
    "\n",
    "    def forward(self, input_values, input_ids, attention_mask):\n",
    "        audio_output = self.audio_model(input_values=input_values)\n",
    "        audio_pooled_output = audio_output[1]\n",
    "\n",
    "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = text_output[0]\n",
    "        text_pooled_output = sequence_output[:, 0]\n",
    "\n",
    "        combined_features = torch.cat((audio_pooled_output, text_pooled_output), dim=1)\n",
    "        class_logits = self.classifier(combined_features)\n",
    "        return class_logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
