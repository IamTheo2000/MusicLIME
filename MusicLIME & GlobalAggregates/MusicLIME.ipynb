{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8b93e8",
   "metadata": {},
   "source": [
    "## MusicLIME\n",
    "\n",
    "The class for multimodal text and audio explanations is provided below. Functions and classes (from AudioLIME) needed to run MusicLIME are also provided in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openunmix\n",
    "#!pip install -q spleeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a450675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenunmixFactorization(SourceSeparationBasedFactorization):\n",
    "    def __init__(self, input, temporal_segmentation_params, composition_fn, target_sr=44100):\n",
    "        super().__init__(input, target_sr, temporal_segmentation_params, composition_fn)\n",
    "\n",
    "    def initialize_components(self):\n",
    "        spleeter_sr = 44100\n",
    "\n",
    "        waveform = self._original_mix\n",
    "        waveform = librosa.resample(waveform, orig_sr=self.target_sr, target_sr=spleeter_sr)\n",
    "        waveform = np.expand_dims(waveform, axis=1)\n",
    "        prediction = predict.separate(torch.as_tensor(waveform).float(), rate=44100)\n",
    "\n",
    "        original_components = [librosa.resample(prediction[key][0].mean(dim=0).numpy(), orig_sr=spleeter_sr,target_sr= self.target_sr) for key in prediction]\n",
    "\n",
    "        components_names = list(prediction.keys())\n",
    "        return original_components, components_names\n",
    "\n",
    "# MusicLIME can be implemented with the original audioLIME factorization function (spleeter)\n",
    "# class SpleeterFactorization(SourceSeparationBasedFactorization):\n",
    "#     def __init__(self, input, temporal_segmentation_params, composition_fn, target_sr=16000,\n",
    "#                  model_name=\"spleeter:5stems\"):\n",
    "#         self.model_name = model_name\n",
    "#         super().__init__(input, target_sr, temporal_segmentation_params, composition_fn)\n",
    "\n",
    "#     def initialize_components(self):\n",
    "#         spleeter_sr = 44100\n",
    "\n",
    "#         waveform = self._original_mix\n",
    "#         separator = Separator(self.model_name, multiprocess=False)\n",
    "#         waveform = librosa.resample(waveform, self.target_sr, spleeter_sr)\n",
    "#         waveform = np.expand_dims(waveform, axis=1)\n",
    "#         prediction = separator.separate(waveform)\n",
    "\n",
    "#         original_components = [\n",
    "#             librosa.resample(np.mean(prediction[key], axis=1), spleeter_sr, self.target_sr) for\n",
    "#             key in prediction]\n",
    "\n",
    "#         components_names = list(prediction.keys())\n",
    "#         return original_components, components_names\n",
    "\n",
    "class LimeMusicExplainer(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 kernel_width=25,\n",
    "                 kernel=None,\n",
    "                 verbose=False,\n",
    "                 class_names=None,\n",
    "                 feature_selection='auto',\n",
    "                 absolute_feature_sort=False,\n",
    "                 split_expression=r'\\W+',\n",
    "                 bow=True,\n",
    "                 mask_string=None,\n",
    "                 random_state=None,\n",
    "                 char_level=False):\n",
    "        kernel_width = float(kernel_width)\n",
    "\n",
    "        if kernel is None:\n",
    "            def kernel(d, kernel_width):\n",
    "                return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))\n",
    "\n",
    "        kernel_fn = partial(kernel, kernel_width=kernel_width)\n",
    "\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.feature_selection = feature_selection\n",
    "        self.base = lime_base.LimeBase(kernel_fn, verbose, absolute_feature_sort)\n",
    "        self.class_names = class_names\n",
    "        self.vocabulary = None\n",
    "        self.feature_selection = feature_selection\n",
    "        self.bow = bow\n",
    "        self.mask_string = mask_string\n",
    "        self.split_expression = split_expression\n",
    "        self.char_level = char_level\n",
    "\n",
    "    def explain_instance(self,\n",
    "                         factorization,\n",
    "                         text_instance,\n",
    "                         predict_fn,\n",
    "                         labels=None,\n",
    "                         top_labels=None,\n",
    "                         num_reg_targets=None,\n",
    "                         num_features=100000,\n",
    "                         num_samples=1000,\n",
    "                         batch_size=10,\n",
    "                         distance_metric='cosine',\n",
    "                         model_regressor=None,\n",
    "                         random_seed=None,\n",
    "                         fit_intercept=True,\n",
    "                         modality='both'):\n",
    "        if labels or top_labels:\n",
    "            is_classification = True\n",
    "        if is_classification and num_reg_targets:\n",
    "            raise ValueError('Set labels or top_labels for classification. '\n",
    "                             'Set num_reg_targets for regression.')\n",
    "        if modality not in ['both', 'lyrical', 'audio']:\n",
    "             raise ValueError('Set modality arguement to \"both\", \"lyrical\" or \"audio\".')\n",
    "\n",
    "        if random_seed is None:\n",
    "            random_seed = self.random_state.randint(0, high=1000)\n",
    "\n",
    "        self.factorization = factorization\n",
    "        top = labels\n",
    "\n",
    "        indexed_string = (lime_text.IndexedCharacters(text_instance, bow=self.bow, mask_string=self.mask_string) if self.char_level else\n",
    "                          lime_text.IndexedString(text_instance, bow=self.bow, split_expression=self.split_expression, mask_string=self.mask_string))\n",
    "        domain_mapper = lime_text.TextDomainMapper(indexed_string)\n",
    "\n",
    "        data, labels, distances = self.combined_data_labels_distances(indexed_string, predict_fn,\n",
    "        \tnum_samples, batch_size=batch_size, distance_metric=distance_metric, modality=modality)\n",
    "\n",
    "        ret_exp = MultimodalExplanation(indexed_string, self.factorization, data, labels, modality=modality)\n",
    "\n",
    "        if top_labels:\n",
    "            top = np.argsort(labels[0])[-top_labels:]\n",
    "            ret_exp.top_labels = list(top)\n",
    "            ret_exp.top_labels.reverse()\n",
    "        for label in top:\n",
    "            (ret_exp.intercept[label],\n",
    "             ret_exp.local_exp[label],\n",
    "             ret_exp.score[label], ret_exp.local_pred[label]) = self.base.explain_instance_with_data(\n",
    "                data, labels, distances, label, num_features,\n",
    "                model_regressor=model_regressor,\n",
    "                feature_selection=self.feature_selection,\n",
    "                )\n",
    "\n",
    "        return ret_exp\n",
    "\n",
    "    def combined_data_labels_distances(self,\n",
    "                                       indexed_string,\n",
    "                                       predict_fn,\n",
    "                                       num_samples,\n",
    "                                       modality,\n",
    "                                       batch_size=10,\n",
    "                                       distance_metric='cosine'):\n",
    "\n",
    "        doc_size = indexed_string.num_words()\n",
    "        audio_size = self.factorization.get_number_components()\n",
    "\n",
    "        if modality == 'both':\n",
    "            total_features = doc_size + audio_size\n",
    "        elif modality == 'lyrical':\n",
    "            total_features = doc_size\n",
    "        elif modality == 'audio':\n",
    "            total_features = audio_size\n",
    "\n",
    "        data = self.random_state.randint(0, 2, num_samples * (total_features))\\\n",
    "        \t.reshape((num_samples, total_features))\n",
    "        data[0, :] = 1\n",
    "\n",
    "        labels = []\n",
    "        audios = []\n",
    "        texts = []\n",
    "\n",
    "        for row  in data:\n",
    "            if modality == 'both':\n",
    "                non_zeros = np.where(row[:audio_size] != 0)[0]\n",
    "                temp = self.factorization.compose_model_input(non_zeros)\n",
    "                audios.append(temp)\n",
    "\n",
    "                inactive = np.where(row[audio_size:] == 0)[0]\n",
    "                perturbed_string = indexed_string.inverse_removing(inactive)\n",
    "                texts.append(perturbed_string)\n",
    "\n",
    "            if modality == 'audio':\n",
    "                non_zeros = np.where(row != 0)[0]\n",
    "                temp = self.factorization.compose_model_input(non_zeros)\n",
    "                audios.append(temp)\n",
    "\n",
    "                inactive = np.array([])\n",
    "                perturbed_string = indexed_string.inverse_removing(inactive)\n",
    "                texts.append(perturbed_string)\n",
    "\n",
    "            if modality == 'lyrical':\n",
    "                all_oness = np.ones(audio_size)\n",
    "                non_zeros = np.where(all_oness != 0)[0]\n",
    "                temp = self.factorization.compose_model_input(non_zeros)\n",
    "                audios.append(temp)\n",
    "\n",
    "                inactive = np.where(row == 0)[0]\n",
    "                perturbed_string = indexed_string.inverse_removing(inactive)\n",
    "                texts.append(perturbed_string)\n",
    "\n",
    "            if len(audios) == batch_size:\n",
    "              preds = predict_fn(texts ,np.array(audios))\n",
    "              labels.extend(preds)\n",
    "              audios = []\n",
    "              texts = []\n",
    "\n",
    "        if len(audios) > 0:\n",
    "            preds = predict_fn(texts ,np.array(audios))\n",
    "            labels.extend(preds)\n",
    "\n",
    "        distances = sklearn.metrics.pairwise_distances(data, data[0].reshape(1, -1), metric=distance_metric).ravel()\n",
    "\n",
    "        return data, np.array(labels), distances\n",
    "\n",
    "\n",
    "class MultimodalExplanation(object):\n",
    "    def __init__(self, indexed_string, factorization, neighborhood_data, neighborhood_labels, modality):\n",
    "\n",
    "        self.factorization = factorization\n",
    "        self.indexed_string = indexed_string\n",
    "        self.neighborhood_data = neighborhood_data\n",
    "        self.neighborhood_labels = neighborhood_labels\n",
    "        self.modality= modality\n",
    "        self.intercept = {}\n",
    "        self.local_exp = {}\n",
    "        self.local_pred = {}\n",
    "        self.score = {}\n",
    "        self.distance = {}\n",
    "\n",
    "    def get_sorted_components(self, label, positive_components=True, negative_components=True, num_components='all',\n",
    "                              min_abs_weight=0.0, return_indeces=False):\n",
    "        if label not in self.local_exp:\n",
    "            raise KeyError('Label not in explanation')\n",
    "        if positive_components is False and negative_components is False:\n",
    "            raise ValueError('positive_components, negative_components or both must be True')\n",
    "        n_audio_features = self.factorization.get_number_components()\n",
    "        exp = self.local_exp[label]\n",
    "\n",
    "        w = [[x[0], x[1]] for x in exp]\n",
    "        used_features, weights = np.array(w, dtype=int)[:, 0], np.array(w)[:, 1]\n",
    "\n",
    "        if not negative_components:\n",
    "            pos_weights = np.argwhere(weights > 0)[:, 0]\n",
    "            used_features = used_features[pos_weights]\n",
    "            weights = weights[pos_weights]\n",
    "        elif not positive_components:\n",
    "            neg_weights = np.argwhere(weights < 0)[:, 0]\n",
    "            used_features = used_features[neg_weights]\n",
    "            weights = weights[neg_weights]\n",
    "        if min_abs_weight != 0.0:\n",
    "            abs_weights = np.argwhere(abs(weights) >= min_abs_weight)[:, 0]\n",
    "            used_features = used_features[abs_weights]\n",
    "            weights = weights[abs_weights]\n",
    "\n",
    "        if num_components == 'all':\n",
    "            num_components = len(used_features)\n",
    "        else:\n",
    "            assert(isinstance(num_components, int))\n",
    "\n",
    "        used_features = used_features[:num_components]\n",
    "        weights = weights[:num_components]\n",
    "        components = []\n",
    "        for index in used_features:\n",
    "            if self.modality == 'both':\n",
    "                if index < n_audio_features:\n",
    "                    components.append(self.factorization.get_ordered_component_names()[index])\n",
    "                else:\n",
    "                    components.append(self.indexed_string.word(index - n_audio_features))\n",
    "            elif self.modality == 'lyrical':\n",
    "                components.append(self.indexed_string.word(index))\n",
    "            elif self.modality == 'audio':\n",
    "                components.append(self.factorization.get_ordered_component_names()[index])\n",
    "\n",
    "        if return_indeces:\n",
    "            return components, weights, used_features\n",
    "        return components, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59523e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_composition_fn(x):\n",
    "    return x\n",
    "\n",
    "def load_audio(audio_path, target_sr):\n",
    "    waveform, _ = librosa.load(audio_path, mono=True, sr=target_sr)\n",
    "    return waveform\n",
    "\n",
    "def compute_segments(signal, sr, temporal_segmentation_params=None):\n",
    "    # TODO: parameter for return type (samples, frames, seconds)?\n",
    "    audio_length = len(signal)\n",
    "    explained_length = audio_length\n",
    "    if temporal_segmentation_params is None:\n",
    "        n_temporal_segments_default = min(audio_length // sr, 10) # 1 segment per second, but maximally 10 segments\n",
    "        temporal_segmentation_params = {'type': 'fixed_length',\n",
    "                                        'n_temporal_segments': n_temporal_segments_default}\n",
    "    elif isinstance(temporal_segmentation_params, int):\n",
    "        temporal_segmentation_params = {'type': 'fixed_length',\n",
    "                                        'n_temporal_segments': temporal_segmentation_params}\n",
    "\n",
    "    segmentation_type = temporal_segmentation_params['type']\n",
    "    assert segmentation_type in ['fixed_length', 'manual']\n",
    "\n",
    "    segments = []\n",
    "    if segmentation_type == \"fixed_length\":\n",
    "        n_temporal_segments = temporal_segmentation_params['n_temporal_segments']\n",
    "        samples_per_segment = audio_length // n_temporal_segments\n",
    "\n",
    "        explained_length = samples_per_segment * n_temporal_segments\n",
    "        if explained_length < audio_length:\n",
    "            warnings.warn(\"last {} samples are ignored\".format(audio_length - explained_length))\n",
    "\n",
    "        for s in range(n_temporal_segments):\n",
    "            segment_start = s * samples_per_segment\n",
    "            segment_end = segment_start + samples_per_segment\n",
    "            segments.append((segment_start, segment_end))\n",
    "    elif segmentation_type == \"manual\":\n",
    "        segments = temporal_segmentation_params[\"manual_segments\"]\n",
    "        explained_length = segments[-1][1]  # end of last segment\n",
    "\n",
    "    return segments, explained_length\n",
    "\n",
    "\n",
    "class Factorization(object):\n",
    "    def __init__(self, input, target_sr, temporal_segmentation_params=None, composition_fn=None):\n",
    "        self._audio_path = None\n",
    "        self.target_sr = target_sr\n",
    "        if isinstance(input, str):\n",
    "            self._audio_path = input\n",
    "            input = load_audio(input, target_sr)\n",
    "        self._original_mix = input\n",
    "        if composition_fn is None:\n",
    "            composition_fn = default_composition_fn\n",
    "        self._composition_fn = composition_fn\n",
    "\n",
    "        self.original_components = []\n",
    "        self.components = []\n",
    "        self._components_names = []\n",
    "        self.temporal_segments, self.explained_length = compute_segments(self._original_mix,\n",
    "                                                                         self.target_sr,\n",
    "                                                                         temporal_segmentation_params)\n",
    "\n",
    "    def compose_model_input(self, components=None):\n",
    "        return self._composition_fn(self.retrieve_components(components))\n",
    "\n",
    "    def get_number_components(self):\n",
    "        # TODO: probably no need to overwrite in other classes\n",
    "        return len(self._components_names)\n",
    "\n",
    "    def retrieve_components(self, selection_order=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_ordered_component_names(self): # e.g. instrument names\n",
    "        return self._components_names\n",
    "\n",
    "\n",
    "class TimeOnlyFactorization(Factorization):\n",
    "    # TODO: add other baseline except 0's?\n",
    "    def __init__(self, input, target_sr, temporal_segmentation_params=None, composition_fn=None):\n",
    "        super().__init__(input, target_sr, temporal_segmentation_params, composition_fn)\n",
    "        for i in range(len(self.temporal_segments)):\n",
    "            self._components_names.append(\"T\"+str(i+1))\n",
    "\n",
    "    def retrieve_components(self, selection_order=None):\n",
    "        # TODO: check if selection_order contains out of bounds segments\n",
    "        if selection_order is None:\n",
    "            return self._original_mix\n",
    "        retrieved_mix = np.zeros_like(self._original_mix)\n",
    "        for so in selection_order:\n",
    "            s, e = self.temporal_segments[so]\n",
    "            retrieved_mix[s:e] = self._original_mix[s:e]\n",
    "        return retrieved_mix\n",
    "\n",
    "\n",
    "class SourceSeparationBasedFactorization(Factorization):\n",
    "\n",
    "    def __init__(self, input, target_sr=44100, temporal_segmentation_params=None, composition_fn=None):\n",
    "        super().__init__(input, target_sr, temporal_segmentation_params, composition_fn)\n",
    "        # the following part is specific to each source sep. algorithm\n",
    "        self.original_components, self._components_names = self.initialize_components()\n",
    "        self.prepare_components(0, len(self._original_mix))\n",
    "\n",
    "    def compose_model_input(self, components=None):\n",
    "        sel_sources = self.retrieve_components(selection_order=components)\n",
    "        if len(sel_sources) > 1:\n",
    "            y = sum(sel_sources)\n",
    "        else:\n",
    "            y = sel_sources[0]\n",
    "        return self._composition_fn(y)\n",
    "\n",
    "    def get_number_components(self):\n",
    "        return len(self.components)\n",
    "\n",
    "    def retrieve_components(self, selection_order=None):\n",
    "        if selection_order is None:\n",
    "            return self.components\n",
    "        if len(selection_order) == 0:\n",
    "            return [np.zeros_like(self.components[0])]\n",
    "        return [self.components[o] for o in selection_order]\n",
    "\n",
    "    def get_ordered_component_names(self):\n",
    "        if len(self._components_names) == 0:\n",
    "            raise Exception(\"Components were not named.\")\n",
    "        return self._components_names\n",
    "\n",
    "    def initialize_components(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def prepare_components(self, start_sample, y_length):\n",
    "        # this resets in case temporal segmentation was previously applied\n",
    "        self.components = [\n",
    "            comp[start_sample:start_sample + y_length] for comp in self.original_components]\n",
    "\n",
    "        component_names = []\n",
    "        temporary_components = []\n",
    "        for s, (segment_start, segment_end) in enumerate(self.temporal_segments):\n",
    "            for co in range(self.get_number_components()):\n",
    "                current_component = np.zeros(self.explained_length, dtype=np.float32)\n",
    "                current_component[segment_start:segment_end] = self.components[co][segment_start:segment_end]\n",
    "                temporary_components.append(current_component)\n",
    "                component_names.append(self._components_names[co] + str(s))\n",
    "\n",
    "        self.components = temporary_components\n",
    "        self._components_names = component_names\n",
    "\n",
    "def pickle_dump(x, path):\n",
    "    pickle.dump(x, open(path, \"wb\"))\n",
    "\n",
    "\n",
    "def pickle_load(path):\n",
    "    return pickle.load(open(path, \"rb\"))\n",
    "\n",
    "class LimeBase(object):\n",
    "    \"\"\"Class for learning a locally linear sparse model from perturbed data\"\"\"\n",
    "    def __init__(self,\n",
    "                 kernel_fn,\n",
    "                 verbose=False,\n",
    "                 absolute_feature_sort=False,\n",
    "                 random_state=None):\n",
    "\n",
    "        self.kernel_fn = kernel_fn\n",
    "        self.verbose = verbose\n",
    "        self.absolute_feature_sort = absolute_feature_sort\n",
    "        self.random_state = check_random_state(random_state)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_lars_path(weighted_data, weighted_labels):\n",
    "\n",
    "        x_vector = weighted_data\n",
    "        alphas, _, coefs = lars_path(x_vector,\n",
    "                                     weighted_labels,\n",
    "                                     method='lasso',\n",
    "                                     verbose=False)\n",
    "        return alphas, coefs\n",
    "\n",
    "    def forward_selection(self, data, labels, weights, num_features):\n",
    "        \"\"\"Iteratively adds features to the model\"\"\"\n",
    "        clf = Ridge(alpha=0, fit_intercept=True, random_state=self.random_state)\n",
    "        used_features = []\n",
    "        for _ in range(min(num_features, data.shape[1])):\n",
    "            max_ = -100000000\n",
    "            best = 0\n",
    "            for feature in range(data.shape[1]):\n",
    "                if feature in used_features:\n",
    "                    continue\n",
    "                clf.fit(data[:, used_features + [feature]], labels,\n",
    "                        sample_weight=weights)\n",
    "                score = clf.score(data[:, used_features + [feature]],\n",
    "                                  labels,\n",
    "                                  sample_weight=weights)\n",
    "                if score > max_:\n",
    "                    best = feature\n",
    "                    max_ = score\n",
    "            used_features.append(best)\n",
    "        return np.array(used_features)\n",
    "\n",
    "    def feature_selection(self, data, labels, weights, num_features, method):\n",
    "        \"\"\"Selects features for the model. see explain_instance_with_data to\n",
    "           understand the parameters.\"\"\"\n",
    "        if method == 'none':\n",
    "            return np.array(range(data.shape[1]))\n",
    "        elif method == 'forward_selection':\n",
    "            return self.forward_selection(data, labels, weights, num_features)\n",
    "        elif method == 'highest_weights':\n",
    "            clf = Ridge(alpha=0, fit_intercept=True,\n",
    "                        random_state=self.random_state)\n",
    "            clf.fit(data, labels, sample_weight=weights)\n",
    "\n",
    "            coef = clf.coef_\n",
    "            if sp.sparse.issparse(data):\n",
    "                coef = sp.sparse.csr_matrix(clf.coef_)\n",
    "                weighted_data = coef.multiply(data[0])\n",
    "                # Note: most efficient to slice the data before reversing\n",
    "                sdata = len(weighted_data.data)\n",
    "                argsort_data = np.abs(weighted_data.data).argsort()\n",
    "                # Edge case where data is more sparse than requested number of feature importances\n",
    "                # In that case, we just pad with zero-valued features\n",
    "                if sdata < num_features:\n",
    "                    nnz_indexes = argsort_data[::-1]\n",
    "                    indices = weighted_data.indices[nnz_indexes]\n",
    "                    num_to_pad = num_features - sdata\n",
    "                    indices = np.concatenate((indices, np.zeros(num_to_pad, dtype=indices.dtype)))\n",
    "                    indices_set = set(indices)\n",
    "                    pad_counter = 0\n",
    "                    for i in range(data.shape[1]):\n",
    "                        if i not in indices_set:\n",
    "                            indices[pad_counter + sdata] = i\n",
    "                            pad_counter += 1\n",
    "                            if pad_counter >= num_to_pad:\n",
    "                                break\n",
    "                else:\n",
    "                    nnz_indexes = argsort_data[sdata - num_features:sdata][::-1]\n",
    "                    indices = weighted_data.indices[nnz_indexes]\n",
    "                return indices\n",
    "            else:\n",
    "                weighted_data = coef * data[0]\n",
    "                feature_weights = sorted( # TODO: check if abs should be optional\n",
    "                    zip(range(data.shape[1]), weighted_data),\n",
    "                    key=lambda x: np.abs(x[1]),\n",
    "                    reverse=True)\n",
    "                return np.array([x[0] for x in feature_weights[:num_features]])\n",
    "        elif method == 'lasso_path':\n",
    "            weighted_data = ((data - np.average(data, axis=0, weights=weights))\n",
    "                             * np.sqrt(weights[:, np.newaxis]))\n",
    "            weighted_labels = ((labels - np.average(labels, weights=weights))\n",
    "                               * np.sqrt(weights))\n",
    "            nonzero = range(weighted_data.shape[1])\n",
    "            _, coefs = self.generate_lars_path(weighted_data,\n",
    "                                               weighted_labels)\n",
    "            for i in range(len(coefs.T) - 1, 0, -1):\n",
    "                nonzero = coefs.T[i].nonzero()[0]\n",
    "                if len(nonzero) <= num_features:\n",
    "                    break\n",
    "            used_features = nonzero\n",
    "            return used_features\n",
    "        elif method == 'auto':\n",
    "            if num_features <= 6:\n",
    "                n_method = 'forward_selection'\n",
    "            else:\n",
    "                n_method = 'highest_weights'\n",
    "            return self.feature_selection(data, labels, weights,\n",
    "                                          num_features, n_method)\n",
    "\n",
    "    def explain_instance_with_data(self,\n",
    "                                   neighborhood_data,\n",
    "                                   neighborhood_labels,\n",
    "                                   distances,\n",
    "                                   label,\n",
    "                                   num_features,\n",
    "                                   feature_selection='auto',\n",
    "                                   model_regressor=None,\n",
    "                                   fit_intercept=True):\n",
    "\n",
    "\n",
    "        weights = self.kernel_fn(distances)\n",
    "        labels_column = neighborhood_labels[:, label]\n",
    "        used_features = self.feature_selection(neighborhood_data,\n",
    "                                               labels_column,\n",
    "                                               weights,\n",
    "                                               num_features,\n",
    "                                               feature_selection)\n",
    "        if model_regressor is None:\n",
    "            model_regressor = Ridge(alpha=1, fit_intercept=fit_intercept,\n",
    "                                    random_state=self.random_state)\n",
    "        easy_model = model_regressor\n",
    "        easy_model.fit(neighborhood_data[:, used_features],\n",
    "                       labels_column, sample_weight=weights)\n",
    "        prediction_score = easy_model.score(\n",
    "            neighborhood_data[:, used_features],\n",
    "            labels_column, sample_weight=weights)\n",
    "\n",
    "        local_pred = easy_model.predict(neighborhood_data[0, used_features].reshape(1, -1))\n",
    "\n",
    "        if self.absolute_feature_sort:\n",
    "            sorted_local_exp = sorted(zip(used_features, easy_model.coef_),\n",
    "                   key=lambda x: np.abs(x[1]), reverse=True)\n",
    "        else:\n",
    "            sorted_local_exp = sorted(zip(used_features, easy_model.coef_),\n",
    "                                  key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Intercept:', easy_model.intercept_)\n",
    "            print('Prediction_local:', local_pred,)\n",
    "            print('Right:', neighborhood_labels[0, label])\n",
    "            print('Score:', prediction_score)\n",
    "        return (easy_model.intercept_,\n",
    "                sorted_local_exp,\n",
    "                prediction_score, local_pred)\n",
    "\n",
    "class AudioExplanation(object):\n",
    "    def __init__(self, factorization, neighborhood_data, neighborhood_labels):\n",
    "        \"\"\"Init function.\n",
    "\n",
    "        Args:\n",
    "            factorization: a Factorization object\n",
    "        \"\"\"\n",
    "        self.factorization = factorization\n",
    "        self.neighborhood_data = neighborhood_data\n",
    "        self.neighborhood_labels = neighborhood_labels\n",
    "        self.intercept = {}\n",
    "        self.local_exp = {}\n",
    "        self.local_pred = {}\n",
    "        self.score = {}\n",
    "        self.distance = {}\n",
    "\n",
    "    def get_sorted_components(self, label, positive_components=True, negative_components=True, num_components='all',\n",
    "                              min_abs_weight=0.0, return_indeces=False):\n",
    "        if label not in self.local_exp:\n",
    "            raise KeyError('Label not in explanation')\n",
    "        if positive_components is False and negative_components is False:\n",
    "            raise ValueError('positive_components, negative_components or both must be True')\n",
    "        if num_components == 'auto':\n",
    "            raise ValueError(\"num_components='auto' was removed.\")\n",
    "\n",
    "        exp = self.local_exp[label]\n",
    "\n",
    "        w = [[x[0], x[1]] for x in exp]\n",
    "        used_features, weights = np.array(w, dtype=int)[:, 0], np.array(w)[:, 1]\n",
    "\n",
    "        if not negative_components:\n",
    "            pos_weights = np.argwhere(weights > 0)[:, 0]\n",
    "            used_features = used_features[pos_weights]\n",
    "            weights = weights[pos_weights]\n",
    "        elif not positive_components:\n",
    "            neg_weights = np.argwhere(weights < 0)[:, 0]\n",
    "            used_features = used_features[neg_weights]\n",
    "            weights = weights[neg_weights]\n",
    "        if min_abs_weight != 0.0:\n",
    "            abs_weights = np.argwhere(abs(weights) >= min_abs_weight)[:, 0]\n",
    "            used_features = used_features[abs_weights]\n",
    "            weights = weights[abs_weights]\n",
    "\n",
    "        if num_components == 'all':\n",
    "            num_components = len(used_features)\n",
    "        else:\n",
    "            assert(isinstance(num_components, int))\n",
    "\n",
    "        used_features = used_features[:num_components]\n",
    "        components = self.factorization.retrieve_components(used_features)\n",
    "        if return_indeces:\n",
    "            return components, used_features\n",
    "        return components\n",
    "\n",
    "    def get_detailed_components(self, label, positive_components=True, negative_components=True, num_components='all', min_abs_weight=0.0, return_indices=False):\n",
    "        components, used_indices = self.get_sorted_components(label, positive_components, negative_components, num_components, min_abs_weight, return_indeces=True)\n",
    "        detailed_labels = []\n",
    "\n",
    "        for index in used_indices:\n",
    "            component_label = self.factorization.get_ordered_component_names()[index]\n",
    "            detailed_labels.append(component_label)\n",
    "\n",
    "        component_details = zip(detailed_labels, components)\n",
    "        detailed_components_list = [{\"label\": label, \"weight\": weight} for label, weight in component_details]\n",
    "\n",
    "        return detailed_components_list\n",
    "\n",
    "\n",
    "class LimeAudioExplainer(object):\n",
    "    \"\"\"Explains predictions on audio data.\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_width=.25, kernel=None, verbose=False,\n",
    "                 feature_selection='auto', absolute_feature_sort=False, random_state=None):\n",
    "\n",
    "        kernel_width = float(kernel_width)\n",
    "\n",
    "        if kernel is None:\n",
    "            def kernel(d, kernel_width):\n",
    "                return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))\n",
    "\n",
    "        kernel_fn = partial(kernel, kernel_width=kernel_width)\n",
    "\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.feature_selection = feature_selection\n",
    "        self.base = LimeBase(kernel_fn, verbose, absolute_feature_sort, random_state=self.random_state)\n",
    "\n",
    "    def explain_instance(self, factorization, predict_fn,\n",
    "                         labels=None,\n",
    "                         top_labels=None,\n",
    "                         num_reg_targets=None,\n",
    "                         num_features=100000,\n",
    "                         num_samples=1000,\n",
    "                         batch_size=32,\n",
    "                         distance_metric='cosine',\n",
    "                         model_regressor=None,\n",
    "                         random_seed=None,\n",
    "                         fit_intercept=True):\n",
    "\n",
    "\n",
    "        is_classification = False\n",
    "        if labels or top_labels:\n",
    "            is_classification = True\n",
    "        if is_classification and num_reg_targets:\n",
    "            raise ValueError('Set labels or top_labels for classification. '\n",
    "                             'Set num_reg_targets for regression.')\n",
    "\n",
    "        if random_seed is None:\n",
    "            random_seed = self.random_state.randint(0, high=1000)\n",
    "\n",
    "        self.factorization = factorization\n",
    "        top = labels\n",
    "\n",
    "        data, labels = self.data_labels(predict_fn, num_samples,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "        distances = sklearn.metrics.pairwise_distances(\n",
    "            data,\n",
    "            data[0].reshape(1, -1),\n",
    "            metric=distance_metric\n",
    "        ).ravel()\n",
    "\n",
    "        ret_exp = AudioExplanation(self.factorization, data, labels)\n",
    "\n",
    "        if is_classification:\n",
    "            if top_labels:\n",
    "                top = np.argsort(labels[0])[-top_labels:]\n",
    "                ret_exp.top_labels = list(top)\n",
    "                ret_exp.top_labels.reverse()\n",
    "            for label in top:\n",
    "                (ret_exp.intercept[label],\n",
    "                 ret_exp.local_exp[label],\n",
    "                 ret_exp.score[label], ret_exp.local_pred[label]) = self.base.explain_instance_with_data(\n",
    "                    data, labels, distances, label, num_features,\n",
    "                    model_regressor=model_regressor,\n",
    "                    feature_selection=self.feature_selection,\n",
    "                    fit_intercept=fit_intercept)\n",
    "        else:\n",
    "            for target in range(num_reg_targets):\n",
    "                (ret_exp.intercept[target],\n",
    "                 ret_exp.local_exp[target],\n",
    "                 ret_exp.score[target],\n",
    "                 ret_exp.local_pred[target]) = self.base.explain_instance_with_data(\n",
    "                    data, labels, distances, target, num_features,\n",
    "                    model_regressor=model_regressor,\n",
    "                    feature_selection=self.feature_selection,\n",
    "                    fit_intercept=fit_intercept)\n",
    "        return ret_exp\n",
    "\n",
    "    def data_labels(self,\n",
    "                    predict_fn,\n",
    "                    num_samples,\n",
    "                    batch_size=10):\n",
    "\n",
    "        n_features = self.factorization.get_number_components()\n",
    "        if num_samples == 'exhaustive':\n",
    "            import itertools\n",
    "            num_samples = 2**n_features\n",
    "            data = np.array(list(map(list, itertools.product([1, 0], repeat=n_features))))\n",
    "        else:\n",
    "            data = self.random_state.randint(0, 2, num_samples * n_features) \\\n",
    "                .reshape((num_samples, n_features))\n",
    "            data[0, :] = 1  # first row all is set to 1\n",
    "\n",
    "        labels = []\n",
    "        audios = []\n",
    "        for row in data:\n",
    "            non_zeros = np.where(row != 0)[0]\n",
    "            temp = self.factorization.compose_model_input(non_zeros)\n",
    "            audios.append(temp)\n",
    "            if len(audios) == batch_size:\n",
    "                preds = predict_fn(np.array(audios))\n",
    "                labels.extend(preds)\n",
    "                audios = []\n",
    "        if len(audios) > 0:\n",
    "            preds = predict_fn(np.array(audios))\n",
    "            labels.extend(preds)\n",
    "        return data, np.array(labels)o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
